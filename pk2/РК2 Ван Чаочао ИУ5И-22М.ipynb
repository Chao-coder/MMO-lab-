{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5821c492",
   "metadata": {},
   "source": [
    "# Рубежный контроль №2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17ff539",
   "metadata": {},
   "source": [
    "Необходимо подготовить отчет по рубежному контролю и разместить его в Вашем репозитории. Вы можете использовать титульный лист, или в начале ноутбука в текстовой ячейке указать Ваши Ф.И.О. и группу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd508a51",
   "metadata": {},
   "source": [
    "# Тема: Методы обработки текстов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e6e1b",
   "metadata": {},
   "source": [
    "# Решение задачи классификации текстов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed5d2f",
   "metadata": {},
   "source": [
    "Необходимо решить задачу классификации текстов на основе любого выбранного Вами датасета (кроме примера, который рассматривался в лекции). Классификация может быть бинарной или многоклассовой. Целевой признак из выбранного Вами датасета может иметь любой физический смысл, примером является задача анализа тональности текста."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32b42e1",
   "metadata": {},
   "source": [
    "Необходимо сформировать два варианта векторизации признаков - на основе CountVectorizer и на основе TfidfVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65312382",
   "metadata": {},
   "source": [
    "В качестве классификаторов необходимо использовать два классификатора по варианту для Вашей группы:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a35d79",
   "metadata": {},
   "source": [
    "ИУ5-22М, ИУ5И-22М\tRandomForestClassifier\tComplement Naive Bayes - CNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eba972c",
   "metadata": {},
   "source": [
    "Для каждого метода необходимо оценить качество классификации. Сделайте вывод о том, какой вариант векторизации признаков в паре с каким классификатором показал лучшее качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e718b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC, NuSVC, OneClassSVM, SVR, NuSVR, LinearSVR\n",
    "\n",
    "%matplotlib inline \n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# !pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c64457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
    "data = newsgroups['data']\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58260315",
   "metadata": {},
   "source": [
    "# Анализируем датасет и готовим категориальный признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15a76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87ac054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество сформированных признаков - 34118\n"
     ]
    }
   ],
   "source": [
    "vocabVect = CountVectorizer()\n",
    "vocabVect.fit(data)\n",
    "corpusVocab = vocabVect.vocabulary_\n",
    "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5429def0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rych=27180\n",
      "festival=13876\n",
      "ed=12325\n",
      "ac=4289\n",
      "uk=31720\n",
      "hawkes=15898\n",
      "subject=29644\n",
      "3ds=2362\n",
      "where=33286\n"
     ]
    }
   ],
   "source": [
    "for i in list(corpusVocab)[1:10]:\n",
    "    print('{}={}'.format(i, corpusVocab[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72e0a707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2034x34118 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 323433 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = vocabVect.transform(data)\n",
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca710eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
    "    for v in vectorizers_list:\n",
    "        for c in classifiers_list:\n",
    "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
    "            score = cross_val_score(pipeline1, newsgroups['data'], newsgroups['target'], scoring='accuracy', cv=3).mean()\n",
    "            print('Векторизация - {}'.format(v))\n",
    "            print('Модель для классификации - {}'.format(c))\n",
    "            print('Accuracy = {}'.format(score))\n",
    "            print('===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66e4a04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '00000': 3,\n",
      "                            '000000': 4, '000005102000': 5, '000021': 6,\n",
      "                            '000062david42': 7, '0000vec': 8, '0001': 9,\n",
      "                            '000100255pixel': 10, '000406': 11, '00041032': 12,\n",
      "                            '0004136': 13, '0004246': 14, '0004422': 15,\n",
      "                            '00044513': 16, '0004847546': 17, '0005': 18,\n",
      "                            '0007': 19, '00090711': 20, '000usd': 21,\n",
      "                            '0010580b': 22, '001125': 23, '0012': 24,\n",
      "                            '001200201pixel': 25, '001428': 26, '001555': 27,\n",
      "                            '001718': 28, '001757': 29, ...})\n",
      "Модель для классификации - RandomForestClassifier()\n",
      "Accuracy = 0.8795476892822025\n",
      "===========================\n",
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '00000': 3,\n",
      "                            '000000': 4, '000005102000': 5, '000021': 6,\n",
      "                            '000062david42': 7, '0000vec': 8, '0001': 9,\n",
      "                            '000100255pixel': 10, '000406': 11, '00041032': 12,\n",
      "                            '0004136': 13, '0004246': 14, '0004422': 15,\n",
      "                            '00044513': 16, '0004847546': 17, '0005': 18,\n",
      "                            '0007': 19, '00090711': 20, '000usd': 21,\n",
      "                            '0010580b': 22, '001125': 23, '0012': 24,\n",
      "                            '001200201pixel': 25, '001428': 26, '001555': 27,\n",
      "                            '001718': 28, '001757': 29, ...})\n",
      "Модель для классификации - ComplementNB()\n",
      "Accuracy = 0.9523107177974435\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '00000': 3,\n",
      "                            '000000': 4, '000005102000': 5, '000021': 6,\n",
      "                            '000062david42': 7, '0000vec': 8, '0001': 9,\n",
      "                            '000100255pixel': 10, '000406': 11, '00041032': 12,\n",
      "                            '0004136': 13, '0004246': 14, '0004422': 15,\n",
      "                            '00044513': 16, '0004847546': 17, '0005': 18,\n",
      "                            '0007': 19, '00090711': 20, '000usd': 21,\n",
      "                            '0010580b': 22, '001125': 23, '0012': 24,\n",
      "                            '001200201pixel': 25, '001428': 26, '001555': 27,\n",
      "                            '001718': 28, '001757': 29, ...})\n",
      "Модель для классификации - RandomForestClassifier()\n",
      "Accuracy = 0.8716814159292037\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '00000': 3,\n",
      "                            '000000': 4, '000005102000': 5, '000021': 6,\n",
      "                            '000062david42': 7, '0000vec': 8, '0001': 9,\n",
      "                            '000100255pixel': 10, '000406': 11, '00041032': 12,\n",
      "                            '0004136': 13, '0004246': 14, '0004422': 15,\n",
      "                            '00044513': 16, '0004847546': 17, '0005': 18,\n",
      "                            '0007': 19, '00090711': 20, '000usd': 21,\n",
      "                            '0010580b': 22, '001125': 23, '0012': 24,\n",
      "                            '001200201pixel': 25, '001428': 26, '001555': 27,\n",
      "                            '001718': 28, '001757': 29, ...})\n",
      "Модель для классификации - ComplementNB()\n",
      "Accuracy = 0.9341199606686331\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\n",
    "classifiers_list = [RandomForestClassifier(), ComplementNB()]\n",
    "VectorizeAndClassify(vectorizers_list, classifiers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dedc57e",
   "metadata": {},
   "source": [
    "Лучшая точность была у CountVectorizer c ComplementNB - 0.952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c916ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
